version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2182:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9093:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  producer:
    build:
      context: .
      dockerfile: docker/producer/Dockerfile
    container_name: crypto-producer
    depends_on:
      - kafka
      - zookeeper
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    restart: on-failure

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7078:7077"
    environment:
      - SPARK_MODE=master

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1

  postgres:
    image: timescale/timescaledb:latest-pg14
    container_name: timescaledb
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./src/sql/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./docker/postgres/ssl:/etc/postgresql/ssl:ro
      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./docker/postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    command: [ "postgres", "-c", "config_file=/etc/postgresql/postgresql.conf" ]

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_SECURITY_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioning/dashboards/json/crypto-dashboard.json
      - GF_DASHBOARDS_VERSIONS_TO_KEEP=20
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources

  spark-app:
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-app
    volumes:
      - ./src/spark:/app/spark
      - ./docker/postgres/ssl/root.crt:/root/.postgresql/root.crt
    depends_on:
      - spark-master
      - kafka
      - postgres
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark-master:7077

  price-alert:
    build:
      context: .
      dockerfile: docker/consumer/Dockerfile
    container_name: price-alert
    volumes:
      - ./src/consumer:/app/consumer
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    command: [ "python", "-u", "/app/consumer/price_alert_consumer.py" ]
    restart: on-failure

volumes:
  postgres_data:
  grafana_data:
